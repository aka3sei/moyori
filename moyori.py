import streamlit as st
import requests
import pandas as pd
import urllib.parse

st.set_page_config(page_title="æœ€å¯„ã‚Šé§…æ¤œç´¢", layout="centered")

# ãƒ˜ãƒƒãƒ€ãƒ¼éè¡¨ç¤º
st.markdown("""
    <style>
    header[data-testid="stHeader"] { visibility: hidden; }
    .block-container { padding-top: 2rem; }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸš‰ æœ€å¯„ã‚Šé§…æ¤œç´¢ï¼ˆè©³ç´°ç‰ˆï¼‰")

address = st.text_input("ä½æ‰€ã‚„åœ°åã‚’å…¥åŠ›", placeholder="ä¾‹ï¼šæ–°å®¿ä¸‰ä¸ç›®")

if address:
    # 1. åº§æ¨™å–å¾—ï¼ˆå›½åœŸåœ°ç†é™¢ï¼‰
    geo_url = f"https://msearch.gsi.go.jp/address-search/AddressSearch?q={address}"
    
    try:
        geo_res = requests.get(geo_url, timeout=5).json()
        if geo_res:
            lon, lat = geo_res[0]['geometry']['coordinates']
            
            # 2. é§…åãƒªã‚¹ãƒˆã®å–å¾—ï¼ˆHeartRails APIï¼‰
            # å¤±æ•—ã—ã«ãã„ã‚ˆã†ã«ãƒªãƒˆãƒ©ã‚¤è¨­å®š
            station_url = f"https://express.heartrails.com/api/json?method=getStations&x={lon}&y={lat}"
            
            stations = []
            with st.spinner('é§…åã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...'):
                try:
                    # ãƒªãƒˆãƒ©ã‚¤ã‚’å«ã‚ãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                    st_res = requests.get(station_url, timeout=10).json()
                    stations = st_res.get('response', {}).get('station', [])
                except:
                    pass

            # 3. é§…åãƒªã‚¹ãƒˆã®è¡¨ç¤º
            if stations:
                st.subheader("ğŸ“‹ å‘¨è¾ºé§…ä¸€è¦§")
                res_data = []
                for s in stations:
                    dist_m = int(s.get('distance', 0))
                    walk_min = -(-dist_m // 80)
                    res_data.append({
                        "è·¯ç·š": s.get('line', '-'),
                        "é§…å": s.get('name', '-'),
                        "å¾’æ­©": f"ç´„{walk_min}åˆ†"
                    })
                
                # é‡è¤‡æ’é™¤ã—ã¦è¡¨ç¤º
                df = pd.DataFrame(res_list := res_data).drop_duplicates(subset=['é§…å']).head(5)
                st.table(df)
            else:
                st.info("âš ï¸ é§…åã®è‡ªå‹•å–å¾—ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸‹ã®åœ°å›³ã§é§…åã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

            # 4. åœ°å›³ã®è¡¨ç¤ºï¼ˆGoogleãƒãƒƒãƒ—åŸ‹ã‚è¾¼ã¿ï¼‰
            st.subheader("ğŸ—ºï¸ å‘¨è¾ºåœ°å›³")
            search_query = f"{address} é§…"
            encoded_query = urllib.parse.quote(search_query)
            map_url = f"https://www.google.com/maps/embed/v1/search?key=YOUR_GOOGLE_MAPS_API_KEY_OPTIONAL&q={encoded_query}"
            
            # APIã‚­ãƒ¼ãªã—ã§ã‚‚å‹•ãåŸ‹ã‚è¾¼ã¿æ–¹å¼
            embed_url = f"https://maps.google.com/maps?q={encoded_query}&output=embed&t=m&z=15"
            st.components.v1.iframe(embed_url, height=400)

        else:
            st.error("ä½æ‰€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        st.error("æ¤œç´¢ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
